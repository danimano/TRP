\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{natbib}
\usepackage{graphicx} 
\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{float}
\usepackage{commath}
\usepackage{upgreek}
\usepackage[numbib]{tocbibind}
\usepackage{hyperref}

\title{Tutored Research Project II (temporary title)}
\author{Candice Bentéjac, Anna Csörgő, Dániel Hajtó}

\begin{document}
\maketitle

\begin{abstract}
Spoiler-free abstract that makes you want to read the next X pages of whatever we are going to say.
\end{abstract}

\section{Introduction}
%%% Upside-down pyramid which contains a description of our domain (deep neural networks), presents our topic (visualization of networks and intuition that deeper networks generalize better than large and shallow ones. Present our outline in a fancy and exciting way.

% Description of the domain ----- NEEDS TO BE IMPROVED AND BACKED UP WITH REFERENCES
\paragraph{}Deep Neural Networks, a recent branch of machine learning, are computational models that are based on the neural networks present in living organisms' brains. Not only do those neural networks allow us to process information, but they also make us able to learn, an ability computers are lacking of. Indeed, unlike the brain as a biological neural network which can reorganize itself and learn to compensate errors, computers are dependent on us to formulate problems as algorithms before being able to solve them. However, there are problems that cannot be formulated as algorithms, causing computers to fail where a human brain would succeed.

\paragraph{}Deep Neural Networks are aiming at allowing, abstractly speaking, a computer to learn by itself, as our brain would. They do not need to be explicitly programmed: they are able to learn from training examples. More precisely, they are able, after a successful training, to generalize a problem and associate data by themselves, without further human intervention. This allows Deep Neural Networks to solve problems where other models are struggling or failing.


\paragraph{}These models have generated a great excitement in the domain of machine learning over the past few years because of the many breakthroughs they led to in domains like computer vision or speech recognition. If Deep Neural Networks have proven themselves to be an efficient way to solve problems, we are yet unable to understand and predict how they map and tune their parameters because of the infinite number of possibilities.

% Presentation of our topic
\paragraph{}In this report of our Tutored Research Project, we focus on two specific concerns that the study of Deep Neural Networks is raising. The first one is about the networks' visualization: in order to better understand how the Deep Neural Networks are optimizing themselves, we might want to gain insights from a direct visualization of the decisions that the networks are taking. To that effect, we built a library that offers its users to precisely visualize the decision boundaries that a given network is determining for each of its layers. The second of our concerns regards the type of network that has the best ability to approximate functions. We thus made a comparison between two different types of network's structures: a shallow one and a deep one. Putting them through the same training and testing conditions, we attempted to draw a general conclusion based on our results about which type network would be, generally speaking, more adapted to problem solving. 

% Outline
\paragraph{}To start with, we will thus review the already existing visualization solutions as well as the studies that have been conducted on the correlation between a network's structure and its ability to generalize. The following section will be dedicated to describing the requirements we had to follow for both of our tasks, before describing the software architecture of our library. We will then comment our implementation and finally, present the tests we ran and the results they produced.




\section{State-of-the-art / Existing solutions}
If relevant, can be a synthesis of the work done in Madrid but it seems like it won't be the case. For the state-of-the-art and existing solutions:


- for the visualization part, there are not really existing solutions to the precise things we want to achieve, but the TensorFlow Playground is already a good and interesting neural network visualization tool that might be worth mentioning.


- for the intuition part (deeper networks crush shallow networks), mention paper \citep{Mhaskar17}, do some other research.


\section{Software requirements}
\paragraph{}Our research project is divided into two main parts. The first one consists in building a library that could be used by anyone willing to work with neural networks and improve their network optimization phase. Additionally, we will develop a program using that library that allows a user to visualize the organization of an input network as well as its decision boundaries. The second part consists in checking experimentally whether small and deep networks tend to generalize better than large and shallow ones. In order to do this, we will build different networks and evaluate their ability to approximate greyscale images of various difficulties. We will then build plots out of our test results to analyze them and assess our intuition.

\paragraph{}In this section, we will present our requirements, listing for each part of our project the constraints, the functional needs, and the non-functional needs. 

\subsection{Part I}
\subsubsection{Constraints}
\begin{itemize}
\item The library and the program will both be developed using Python.
\item The networks involved should only use the ReLU operator. 
\item The program should only take as an input a network and its parameters saved in a TensorFlow file.
\item The program should display all the layers of the network with different colors.
\end{itemize}

\subsubsection{Needs}
\noindent\textbf{Functional needs}
\begin{itemize}
\item The library should be able to be called by a user building their own networks and trying to optimize them.
\item The program should have a graphical user interface (GUI).
\item The program should display the network, given as an input by the user, by drawing all its decision boundaries for all neurons, on all layers. 
\item The program should be able to display all the layers and neurons at the same time if requested by the user, no matter how big the input network is.
\item The user should be able to choose which layer are being displayed by the program. 
\item The user should be able to save the network visualization displayed by the program as a .jpg image.
\item The user should be able to choose which part of the plane shown by the program they want to see and change it as they want. By default, the region of the plane to be shown will be set automatically. 

\end{itemize}
\noindent\textbf{Non-functional needs}
\begin{itemize}
\item For each region displayed by the program, the slope of the visible decision boundaries should also be displayed.
\end{itemize}

\subsection{Part II}
\subsubsection{Constraints}
\begin{itemize}
\item The experiments should be developed and run using Python.
\item All the neural networks built for the experiments should be created and used with TensorFlow.
\item All the images used for our experiments should be of a format that can be handled by TensorFlow neural network. 
\item All plots should be plotted using Matplotlib.
\item Only greyscale images should be used as inputs for our experiments.
\item The images used as inputs for our experiments should be of different types and difficulties: synthetic simple images (such as a black square on a white background), synthetic images with noise, synthetic textures, and real images.
\item The method of least squares should be used to evaluate the networks' abilities to approximate the input images.
\item A single network should be used for a single image.
\end{itemize}

\subsubsection{Needs}
\noindent\textbf{Functional needs}
\begin{itemize}
\item Neural networks should be created, trained on images, and their ability of approximating those images should be assessed. 
\item A parameter should determine how many percents of the input image's pixels will be used for the training phase.
\item 100\% of the input image's pixels should be used during the testing phase.
\item The input of a neural network should be the location of an input image's pixel.
\item For one experiment with a given input, the same number of parameters should be used for all the networks. Only the structure of the networks should vary.
\item The generated plots should be the curves of the least square error (on the $y$ axis) depending on the number of layers and the total number of parameters (on the $x$ axis). A curve should correspond to a specific number of layers.
\item On every plot, each point in the curve should be an average over several trials using different training sets.

\end{itemize}

\section{Software architecture}
(ULM schemes), how our software is organized, what our modules are. Also insert a magnificently beautiful Gantt chart.

\section{Implementation}
Explain which algorithms we used or what algorithms we wrote specifically for our project. Basically, speak of the code content in a comprehensive and appealing way.

\section{Tests}
Explain which tests we run and present our results (which will hopefully be outstanding). For both parts, images will be necessary: saved images from our part1 software and curves plotted throughout the second. (Additionally, for the second part, see if saving the weights computed for approximating an image is lighter than saving the image itself.)


\section{Conclusion}
Pyramid that contains a typical yet cool conclusion (yeah, we did this and that and it's working, time to celebrate!), draw actual conclusions from our results (i.e. are deeper networks experimentally truly better than shallow ones as our intuition suggested? how and why?) and suggests improvements that could be made over what we already did. Future work should also be mentioned.

\bibliographystyle{plain}
\bibliography{bibTRP}

\end{document}