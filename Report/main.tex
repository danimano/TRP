\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{natbib}
\usepackage{graphicx} 
\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{float}
\usepackage{commath}
\usepackage{upgreek}
\usepackage[numbib]{tocbibind}
\usepackage{hyperref}

\title{Tutored Research Project II (temporary title)}
\author{Candice Bentéjac, Anna Csörgő, Dániel Hajtó}

\begin{document}
\maketitle

\begin{abstract}
Spoiler-free abstract that makes you want to read the next X pages of whatever we are going to say.
\end{abstract}

\section{Introduction}
%%% Upside-down pyramid which contains a description of our domain (deep neural networks), presents our topic (visualization of networks and intuition that deeper networks generalize better than large and shallow ones. Present our outline in a fancy and exciting way.

% Description of the domain ----- NEEDS TO BE IMPROVED AND BACKED UP WITH REFERENCES
\paragraph{}Deep Neural Networks, a recent branch of machine learning, are computational models that are based on the neural networks present in living organisms' brains. Not only do those neural networks allow us to process information, but they also make us able to learn, an ability computers are lacking of. Indeed, unlike the brain as a biological neural network which can reorganize itself and learn to compensate errors, computers are dependent on us to formulate problems as algorithms before being able to solve them. However, there are problems that cannot be formulated as algorithms, causing computers to fail where a human brain would succeed.

\paragraph{}Deep Neural Networks are aiming at allowing, abstractly speaking, a computer to learn by itself, as our brain would. They do not need to be explicitly programmed: they are able to learn from training examples. More precisely, they are able, after a successful training, to generalize a problem and associate data by themselves, without further human intervention. This allows Deep Neural Networks to solve problems where other models are struggling or failing.


\paragraph{}These models have generated a great excitement in the domain of machine learning over the past few years because of the many breakthroughs they led to in domains like computer vision or speech recognition. If Deep Neural Networks have proven themselves to be an efficient way to solve problems, we are yet unable to understand and predict how they map and tune their parameters because of the infinite number of possibilities.

% Presentation of our topic
\paragraph{}In this report of our Tutored Research Project, we focus on two specific concerns that the study of Deep Neural Networks is raising. The first one is about the networks' visualization: in order to better understand how the Deep Neural Networks are optimizing themselves, we might want to gain insights from a direct visualization of the decisions that the networks are taking. To that effect, we will build a library that offers its users to precisely visualize the decision boundaries that a given network is determining for each of its layers. The second of our concerns regards the type of network that has the best ability to approximate functions. We thus will make a comparison between two different types of network's structures: a shallow one and a deep one. Putting them through the same training and testing conditions, we will attempt to draw a general conclusion based on our results about which type network would be, generally speaking, more adapted to problem solving. 

% Outline
\paragraph{}To start with, we will therefore review the already existing visualization solutions as well as the studies that have been conducted on the correlation between a network's structure and its ability to generalize. The following section will be dedicated to describing the requirements we had to follow for both of our tasks, before describing the software architecture of our library. We will then comment our implementation and finally, present the tests we ran and the results they produced.




\section{State-of-the-art and existing solutions}
% Can be a synthesis of the work done in Madrid but irrelevant in our case. 
%- for the visualization part, there are not really existing solutions to the precise things we want to achieve, but the TensorFlow Playground is already a good and interesting neural network visualization tool that might be worth mentioning.

%- for the intuition part (deeper networks crush shallow networks), mention paper \citep{Mhaskar17}, do some other research.
\paragraph{}The problems of visualization and structure of Deep Neural Networks have already been studied. When reading articles on Deep Neural Networks, we however noticed that those specifically points had not been widely covered and that many of the articles on them had been written by the same group of people. In this context, our own work on those aspects of neural networks is relevant, since its intent is to complete what has already been uncovered rather than just presenting it in another way. 

\paragraph{}Throughout this section, we will thus present the already existing solutions to the visualization and structure problems, starting with the visualization methods for Deep Neural Networks before speaking of the different comparisons that have been already made between deep and shallow networks.  


\subsection{Visualization of Deep Neural Networks}
\paragraph{}Visualization methods for Deep Neural Networks are relevant, since they might help us getting a better understanding of how the networks are operating and what makes them such powerful models. Obtaining this knowledge is important for various reasons. One of the most important is that, so far, trial-and-error is the main way to find the best set of parameters when training a Deep Neural Network. Besides being time-consuming, it results in networks having thousands or millions of parameters, which only makes it harder to improve them. Indeed, the higher the number of parameters, the harder it gets to find the strengths and weaknesses of the networks. Understanding how the networks are actually learning is thus necessary to improve the training phase of the networks and, by extension, improve networks which have already, through trial-and-error, proven themselves to be successful.

\paragraph{}In this context, \citep{ZintgrafICLR2017} and \citep{Zintgraf2017} present a recent method to visualize the response of a Deep Neural Network to a specific input. For example, when inputting an image, the method will highlight the areas of the image that provide information in favor of or against a certain class. This type of visualization leads to a better understanding of the classification process which the neural network goes through, and how and why a class is chosen rather than another. 

\paragraph{}Another approach to visualize Deep Neural Networks is to focus on the notion of a class, that is to say, what a network understands to be a class. For a given class, it consists in finding an input that will maximize this given class. We can then visualize what the network is looking for in the image to classify it, and thus have an idea of what specifically triggers the network when attempting to classify. \citep{Simonyan2014} use this approach to develop two visualization techniques. The first one visualizes the notion of the class that a convolutional network has by generating an image that maximizes the class score for a given class. The second one is an image-specific class saliency visualization that computes the given class saliency map by ranking the input features, depending on their influence over the given class. \citep{Yosinski2015} also introduce two visualization techniques. One visualizes the activations that are made by a convolutional network as it processes an image or a video, which allows to gain valuable insights on how convolutional networks work. The other consists in visualizing the features at each layer of a Deep Neural Network. To this end, it performs regularized optimization in the image space.

\paragraph{}It seems also important to note that there are very few accessible visualization tools available on-line for a large public that does not necessarily have a great knowledge about Deep Neural Networks. One worth mentioning for people willing to familiarize themselves with Deep Neural Networks and others willing to play around with them is the TensorFlow Playground \citep{TFPlayground}. It allows the user to choose between simple datasets, select how many hidden layers and neurons they want to use, and to set several parameters, including the activation function and the learning rate. Once all the parameters have been set, the Playground displays the network's output for each epoch and lets the user visualize the output of each neuron on each layer.

\subsection{Comparison between deep and shallow networks}
\paragraph{}The depth of Deep Neural Networks has greatly evolved over the past few years. The now well-known AlexNet \citep{Krizhevsky2017} won the 2012 ILSVRC (ImageNet Large-Scale Visual Recognition Challenge) with 7 hidden layers, outperforming by more than 10 percent the other contestants. In 2015, Microsoft ResNet \citep{He2016} won the ILSVRC using 152 layers. Between 2012 and 2015, the winners of each ILSVRC (ZF Net \citep{Zeiler2014}, VGG Net \citep{Simonyan2015} and GoogLeNet \citep{Szegedy2015}) used networks with an increasing number of layers, always achieving better results than those from the previous years. This suggests that deep networks are, at least in the context of image recognition, better than shallow ones and that, the more layers a network has, the better it will perform. 

\paragraph{}\citep{Zagoruyko2016} however show that a deep residual network with "only" 16 layers can outperform all the previous residual networks, even those having a thousand of layers, both in accuracy and efficiency. This indicates that although a deep network seems to perform better than a shallow one, the performance is not determined by the number of layers itself.

\paragraph{}Furthermore, \citep{Mhaskar2016} and \citep{Mhaskar2016May} show that a shallow network and a deep network can approximate the class of compositional functions with the same accuracy. However, a deep network will achieve such a result with an exponentially lower number of training parameters and a lower VC-dimension. 
% VC-space = measure of the capacity of a space of functions that can be learned by a statistical classification algorithm; it is defined as the cardinality of the largest set of points that the algorithm can shatter
\citep{Poggio2017} and \citep{Mhaskar17} further discuss when and under which conditions learning with deep networks can be exponentially better than learning with shallow ones. 

\paragraph{}They state that both shallow and deep networks are universal and can thus approximate arbitrarily well any continuous functions on a compact domain (universal approximation theorem) and consider a class of functions on a compact domain that is a hierarchical composition of local functions. When approximating those functions with a compositional structure, deep networks can represent compositionality in their architecture whereas shallow networks cannot do so and thus do not have any structural information on the function to be learned. Moreover, deep networks are able to exploit the special structure of compositional functions in their architecture when shallow networks are plainly blind to it. It is also not a requirement for the deep networks to have the same compositional architecture as the compositional functions to be approximated: the acyclic graph representing the structure of the function only needs to be a subgraph of the graph representing the deep networks' structure.

\section{Software requirements}
\paragraph{}Our research project is divided into two main parts. The first one consists in building a library that could be used by anyone willing to work with neural networks and to improve their network during their optimization phase. In order to do that, the library will allow the user to visualize the neural network's decision boundaries. Additionally, we will develop a program using that library that lets the user give a file containing a network's parameters as an input, and draws its decision boundaries as a means of visualization of its organization. The second part consists in checking experimentally whether small and deep networks tend to generalize better than large and shallow ones. For this, we will build different networks and evaluate their ability to approximate greyscale images of various difficulties. We will then build plots out of our test results to analyze them and assess our intuition.

\paragraph{}In this section, we will present our requirements, listing for each part of our project the constraints, the functional needs, and the non-functional needs. 

\subsection{Network visualization}
\subsubsection{Constraints}
\begin{itemize}
\item The library and the program will both be developed using Python.
\item The networks involved should only use the ReLU operator. 
\item The program should only take as an input a network and its parameters saved in a TensorFlow file.
\item The program should display all the layers of the network with different colors.
\end{itemize}

\subsubsection{Needs}
\noindent\textbf{Functional needs}
\begin{itemize}
\item The library should be able to be called by a user building their own networks and trying to optimize them by using visualization.
\item The program should have a graphical user interface (GUI).
\item The program should display the network, given as an input by the user, by drawing all its decision boundaries for all neurons, on all layers. 
\item The program should be able to display all the layers and neurons at the same time if requested by the user, no matter how big the input network is.
\item The user should be able to choose which layer are being displayed by the program. 
\item The user should be able to save the network visualization displayed by the program as a .jpg image.
\item The user should be able to choose which part of the plane shown by the program they want to see and change it as they want. By default, the region of the plane to be shown will be set automatically. 

\end{itemize}
\noindent\textbf{Non-functional needs}
\begin{itemize}
\item For each region displayed by the program, the slope of the visible decision boundaries should also be displayed.
\end{itemize}

\subsection{Part II}
\subsubsection{Constraints}
\begin{itemize}
\item The experiments should be developed and run using Python.
\item All the neural networks built for the experiments should be created and used with TensorFlow.
\item All the images used for our experiments should be of a format that can be handled by TensorFlow neural network. 
\item All plots should be plotted using Matplotlib.
\item Only greyscale images should be used as inputs for our experiments.
\item The images used as inputs for our experiments should be of different types and difficulties: synthetic simple images (such as a black square on a white background), synthetic images with noise, synthetic textures, and real images.
\item The method of least squares should be used to evaluate the networks' abilities to approximate the input images.
\item A single network should be used for a single image.
\end{itemize}

\subsubsection{Needs}
\noindent\textbf{Functional needs}
\begin{itemize}
\item Neural networks should be created, trained on images, and their ability of approximating those images should be assessed. 
\item A parameter should determine how many percents of the input image's pixels will be used for the training phase.
\item 100\% of the input image's pixels should be used during the testing phase.
\item The input of a neural network should be the location of an input image's pixel.
\item For one experiment with a given input, the same number of parameters should be used for all the networks. Only the structure of the networks should vary.
\item The generated plots should be the curves of the least square error (on the $y$ axis) depending on the number of layers and the total number of parameters (on the $x$ axis). A curve should correspond to a specific number of layers.
\item On every plot, each point in the curve should be an average over several trials using different training sets.

\end{itemize}

\section{Software architecture}
(ULM schemes), how our software is organized, what our modules are. Also insert a magnificently beautiful Gantt chart.

\section{Implementation}
Explain which algorithms we used or what algorithms we wrote specifically for our project. Basically, speak of the code content in a comprehensive and appealing way.

\section{Tests}
Explain which tests we run and present our results (which will hopefully be outstanding). For both parts, images will be necessary: saved images from our part1 software and curves plotted throughout the second. (Additionally, for the second part, see if saving the weights computed for approximating an image is lighter than saving the image itself.)


\section{Conclusion}
Pyramid that contains a typical yet cool conclusion (yeah, we did this and that and it's working, time to celebrate!), draw actual conclusions from our results (i.e. are deeper networks experimentally truly better than shallow ones as our intuition suggested? how and why?) and suggests improvements that could be made over what we already did. Future work should also be mentioned.

\bibliographystyle{plain}
\bibliography{bibTRP}

\end{document}